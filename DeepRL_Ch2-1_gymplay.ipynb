{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep RL hands-on by Maxim Lapan\n",
    "* conda activate gym \n",
    "  - which will work with torch 1.1, tensorflow 2.0 with CUDA 10\n",
    "* this book use torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "e = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03923938, -0.03779373, -0.01873953,  0.04356973])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = e.reset()\n",
    "obs # return 4 values, x coordinate, speed, angle, angular speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2) Box(4,)\n"
     ]
    }
   ],
   "source": [
    "print(e.action_space, e.observation_space)\n",
    "# action only left and right, space has 4 values with continue value [-inf, inf]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.03999526, -0.23264202, -0.01786814,  0.33028175]), 1.0, False, {})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.step(0) # left action is taken, \n",
    "# new obs, reward, done flag deal with the end of episode.\n",
    "# extra information is {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.action_space.sample() # random action is taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.0481248e+00, -1.5967134e+38, -1.0751937e-01,  1.4390064e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.observation_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.2971123e-01,  2.4631394e+38,  6.5095246e-02, -2.1204253e+38],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## making randomly acting agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    e = gym.make(\"CartPole-v0\")\n",
    "    total_reward = 0.0\n",
    "    total_steps = 0\n",
    "    obs = e.reset()\n",
    "    # initialize the env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 steps, 1 action, total reward 1.00 [ 0.01519388  0.17698302 -0.00110098 -0.24353408]\n",
      "2 steps, 1 action, total reward 2.00 [ 0.01873354  0.37212068 -0.00597166 -0.53656408]\n",
      "3 steps, 0 action, total reward 3.00 [ 0.02617596  0.1770832  -0.01670294 -0.24576873]\n",
      "4 steps, 1 action, total reward 4.00 [ 0.02971762  0.37243968 -0.02161831 -0.54367301]\n",
      "5 steps, 1 action, total reward 5.00 [ 0.03716642  0.56785866 -0.03249177 -0.84308827]\n",
      "6 steps, 1 action, total reward 6.00 [ 0.04852359  0.76340863 -0.04935354 -1.14580931]\n",
      "7 steps, 1 action, total reward 7.00 [ 0.06379176  0.95913919 -0.07226973 -1.45355171]\n",
      "8 steps, 1 action, total reward 8.00 [ 0.08297455  1.15507041 -0.10134076 -1.76791017]\n",
      "9 steps, 0 action, total reward 9.00 [ 0.10607595  0.96122858 -0.13669896 -1.50838242]\n",
      "10 steps, 0 action, total reward 10.00 [ 0.12530053  0.76800283 -0.16686661 -1.26131208]\n",
      "11 steps, 1 action, total reward 11.00 [ 0.14066058  0.96481863 -0.19209285 -1.60126658]\n",
      "12 steps, 1 action, total reward 12.00 [ 0.15995695  1.16162576 -0.22411818 -1.94717603]\n",
      "Episode done in 12 steps, total reward 12.00\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    action = e.action_space.sample() # random action\n",
    "    obs, reward, done, _ = e.step(action) # return the results\n",
    "    total_reward += reward\n",
    "    total_steps += 1\n",
    "    print(\"%d steps, %d action, total reward %.2f\" %(total_steps, action, total_reward), obs)\n",
    "    if done: # if done flag return True, end episode.\n",
    "        break\n",
    "print(\"Episode done in %d steps, total reward %.2f\" %(total_steps, total_reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
